{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Unclean Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'trainingandtestdata/training.1600000.processed.noemoticon.csv' does not exist: b'trainingandtestdata/training.1600000.processed.noemoticon.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d3171f9fa5fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainingandtestdata/training.1600000.processed.noemoticon.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainingandtestdata/testdata.manual.2009.06.14.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'trainingandtestdata/training.1600000.processed.noemoticon.csv' does not exist: b'trainingandtestdata/training.1600000.processed.noemoticon.csv'"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('trainingandtestdata/training.1600000.processed.noemoticon.csv',header=None,encoding = \"ISO-8859-1\")\n",
    "test = pd.read_csv('trainingandtestdata/testdata.manual.2009.06.14.csv',header=None,encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 6)\n",
      "(498, 6)\n"
     ]
    }
   ],
   "source": [
    "## Print size of both train and test data\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mybirch</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>coZZ</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>Mon Apr 06 22:20:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>2Hood4Hollywood</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>Mon Apr 06 22:20:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mimismo</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812416</td>\n",
       "      <td>Mon Apr 06 22:20:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>erinx3leannexo</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812579</td>\n",
       "      <td>Mon Apr 06 22:20:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>pardonlauren</td>\n",
       "      <td>I just re-pierced my ears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812723</td>\n",
       "      <td>Mon Apr 06 22:20:19 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TLeC</td>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812771</td>\n",
       "      <td>Mon Apr 06 22:20:19 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>robrobbierobert</td>\n",
       "      <td>@octolinz16 It it counts, idk why I did either...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812784</td>\n",
       "      <td>Mon Apr 06 22:20:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bayofwolves</td>\n",
       "      <td>@smarrison i would've been the first, but i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812799</td>\n",
       "      <td>Mon Apr 06 22:20:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>HairByJess</td>\n",
       "      <td>@iamjazzyfizzle I wish I got to watch it with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812964</td>\n",
       "      <td>Mon Apr 06 22:20:22 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lovesongwriter</td>\n",
       "      <td>Hollis' death scene will hurt me severely to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1467813137</td>\n",
       "      <td>Mon Apr 06 22:20:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>armotley</td>\n",
       "      <td>about to file taxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1467813579</td>\n",
       "      <td>Mon Apr 06 22:20:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>starkissed</td>\n",
       "      <td>@LettyA ahh ive always wanted to see rent  lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1467813782</td>\n",
       "      <td>Mon Apr 06 22:20:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>gi_gi_bee</td>\n",
       "      <td>@FakerPattyPattz Oh dear. Were you drinking ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1467813985</td>\n",
       "      <td>Mon Apr 06 22:20:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>quanvu</td>\n",
       "      <td>@alydesigns i was out most of the day so didn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1467813992</td>\n",
       "      <td>Mon Apr 06 22:20:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>swinspeedx</td>\n",
       "      <td>one of my friend called me, and asked to meet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1467814119</td>\n",
       "      <td>Mon Apr 06 22:20:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cooliodoc</td>\n",
       "      <td>@angry_barista I baked you a cake but I ated it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1467814180</td>\n",
       "      <td>Mon Apr 06 22:20:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>viJILLante</td>\n",
       "      <td>this week is not going as i had hoped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1467814192</td>\n",
       "      <td>Mon Apr 06 22:20:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Ljelli3166</td>\n",
       "      <td>blagh class at 8 tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1467814438</td>\n",
       "      <td>Mon Apr 06 22:20:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ChicagoCubbie</td>\n",
       "      <td>I hate when I have to call and wake people up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1467814783</td>\n",
       "      <td>Mon Apr 06 22:20:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KatieAngell</td>\n",
       "      <td>Just going to cry myself to sleep after watchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1467814883</td>\n",
       "      <td>Mon Apr 06 22:20:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>gagoo</td>\n",
       "      <td>im sad now  Miss.Lilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1467815199</td>\n",
       "      <td>Mon Apr 06 22:20:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>abel209</td>\n",
       "      <td>ooooh.... LOL  that leslie.... and ok I won't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1467815753</td>\n",
       "      <td>Mon Apr 06 22:21:04 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BaptisteTheFool</td>\n",
       "      <td>Meh... Almost Lover is the exception... this t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599970</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578196</td>\n",
       "      <td>Tue Jun 16 08:38:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>adbillingsley</td>\n",
       "      <td>Thanks @eastwestchic &amp;amp; @wangyip Thanks! Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599971</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578237</td>\n",
       "      <td>Tue Jun 16 08:38:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>gekkko</td>\n",
       "      <td>@marttn thanks Martin. not the most imaginativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599972</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578269</td>\n",
       "      <td>Tue Jun 16 08:38:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>millerslab</td>\n",
       "      <td>@MikeJonesPhoto Congrats Mike  Way to go!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599973</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578319</td>\n",
       "      <td>Tue Jun 16 08:38:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>luckygeorgeblog</td>\n",
       "      <td>http://twitpic.com/7jp4n - OMG! Office Space.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599974</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578345</td>\n",
       "      <td>Tue Jun 16 08:38:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Kristah_Diggs</td>\n",
       "      <td>@yrclndstnlvr ahaha nooo you were just away fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599975</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578347</td>\n",
       "      <td>Tue Jun 16 08:38:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>CoachChic</td>\n",
       "      <td>@BizCoachDeb  Hey, I'm baack! And, thanks so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599976</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578348</td>\n",
       "      <td>Tue Jun 16 08:38:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>serianna</td>\n",
       "      <td>@mattycus Yeah, my conscience would be clear i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599977</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578386</td>\n",
       "      <td>Tue Jun 16 08:38:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TeamUKskyvixen</td>\n",
       "      <td>@MayorDorisWolfe Thats my girl - dishing out t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599978</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578395</td>\n",
       "      <td>Tue Jun 16 08:38:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LaurenMoo10</td>\n",
       "      <td>@shebbs123 i second that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599979</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578576</td>\n",
       "      <td>Tue Jun 16 08:38:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>angel_sammy04</td>\n",
       "      <td>In the garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599980</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578679</td>\n",
       "      <td>Tue Jun 16 08:38:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>puchal_ek</td>\n",
       "      <td>@myheartandmind jo jen by nemuselo zrovna tÃ© ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599981</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578716</td>\n",
       "      <td>Tue Jun 16 08:38:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>youtubelatest</td>\n",
       "      <td>Another Commenting Contest! [;: Yay!!!  http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599982</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578739</td>\n",
       "      <td>Tue Jun 16 08:38:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Mandi_Davenport</td>\n",
       "      <td>@thrillmesoon i figured out how to see my twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599983</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578758</td>\n",
       "      <td>Tue Jun 16 08:38:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>xoAurixo</td>\n",
       "      <td>@oxhot theri tomorrow, drinking coffee, talkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599984</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578847</td>\n",
       "      <td>Tue Jun 16 08:38:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RobFoxKerr</td>\n",
       "      <td>You heard it here first -- We're having a girl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599985</th>\n",
       "      <td>4</td>\n",
       "      <td>2193578982</td>\n",
       "      <td>Tue Jun 16 08:38:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LISKFEST</td>\n",
       "      <td>if ur the lead singer in a band, beware fallin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599986</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579087</td>\n",
       "      <td>Tue Jun 16 08:38:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>marhgil</td>\n",
       "      <td>@tarayqueen too much ads on my blog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599987</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579092</td>\n",
       "      <td>Tue Jun 16 08:38:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cathriiin</td>\n",
       "      <td>@La_r_a NEVEER  I think that you both will get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599988</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579191</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tellman</td>\n",
       "      <td>@Roy_Everitt ha- good job. that's right - we g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599989</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579211</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jazzstixx</td>\n",
       "      <td>@Ms_Hip_Hop im glad ur doing well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599990</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579249</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>razzberry5594</td>\n",
       "      <td>WOOOOO! Xbox is back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599991</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579284</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AgustinaP</td>\n",
       "      <td>@rmedina @LaTati Mmmm  That sounds absolutely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599992</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579434</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sdancingsteph</td>\n",
       "      <td>ReCoVeRiNg FrOm ThE lOnG wEeKeNd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599993</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579477</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ChloeAmisha</td>\n",
       "      <td>@SCOOBY_GRITBOYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579489</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>EvolveTom</td>\n",
       "      <td>@Cliff_Forster Yeah, that does work better tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0           1                             2         3  \\\n",
       "0        0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "5        0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "6        0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "7        0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "8        0  1467811795  Mon Apr 06 22:20:05 PDT 2009  NO_QUERY   \n",
       "9        0  1467812025  Mon Apr 06 22:20:09 PDT 2009  NO_QUERY   \n",
       "10       0  1467812416  Mon Apr 06 22:20:16 PDT 2009  NO_QUERY   \n",
       "11       0  1467812579  Mon Apr 06 22:20:17 PDT 2009  NO_QUERY   \n",
       "12       0  1467812723  Mon Apr 06 22:20:19 PDT 2009  NO_QUERY   \n",
       "13       0  1467812771  Mon Apr 06 22:20:19 PDT 2009  NO_QUERY   \n",
       "14       0  1467812784  Mon Apr 06 22:20:20 PDT 2009  NO_QUERY   \n",
       "15       0  1467812799  Mon Apr 06 22:20:20 PDT 2009  NO_QUERY   \n",
       "16       0  1467812964  Mon Apr 06 22:20:22 PDT 2009  NO_QUERY   \n",
       "17       0  1467813137  Mon Apr 06 22:20:25 PDT 2009  NO_QUERY   \n",
       "18       0  1467813579  Mon Apr 06 22:20:31 PDT 2009  NO_QUERY   \n",
       "19       0  1467813782  Mon Apr 06 22:20:34 PDT 2009  NO_QUERY   \n",
       "20       0  1467813985  Mon Apr 06 22:20:37 PDT 2009  NO_QUERY   \n",
       "21       0  1467813992  Mon Apr 06 22:20:38 PDT 2009  NO_QUERY   \n",
       "22       0  1467814119  Mon Apr 06 22:20:40 PDT 2009  NO_QUERY   \n",
       "23       0  1467814180  Mon Apr 06 22:20:40 PDT 2009  NO_QUERY   \n",
       "24       0  1467814192  Mon Apr 06 22:20:41 PDT 2009  NO_QUERY   \n",
       "25       0  1467814438  Mon Apr 06 22:20:44 PDT 2009  NO_QUERY   \n",
       "26       0  1467814783  Mon Apr 06 22:20:50 PDT 2009  NO_QUERY   \n",
       "27       0  1467814883  Mon Apr 06 22:20:52 PDT 2009  NO_QUERY   \n",
       "28       0  1467815199  Mon Apr 06 22:20:56 PDT 2009  NO_QUERY   \n",
       "29       0  1467815753  Mon Apr 06 22:21:04 PDT 2009  NO_QUERY   \n",
       "...     ..         ...                           ...       ...   \n",
       "1599970  4  2193578196  Tue Jun 16 08:38:54 PDT 2009  NO_QUERY   \n",
       "1599971  4  2193578237  Tue Jun 16 08:38:54 PDT 2009  NO_QUERY   \n",
       "1599972  4  2193578269  Tue Jun 16 08:38:54 PDT 2009  NO_QUERY   \n",
       "1599973  4  2193578319  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599974  4  2193578345  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599975  4  2193578347  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599976  4  2193578348  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599977  4  2193578386  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599978  4  2193578395  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599979  4  2193578576  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599980  4  2193578679  Tue Jun 16 08:38:56 PDT 2009  NO_QUERY   \n",
       "1599981  4  2193578716  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599982  4  2193578739  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599983  4  2193578758  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599984  4  2193578847  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599985  4  2193578982  Tue Jun 16 08:38:58 PDT 2009  NO_QUERY   \n",
       "1599986  4  2193579087  Tue Jun 16 08:38:58 PDT 2009  NO_QUERY   \n",
       "1599987  4  2193579092  Tue Jun 16 08:38:58 PDT 2009  NO_QUERY   \n",
       "1599988  4  2193579191  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599989  4  2193579211  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599990  4  2193579249  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599991  4  2193579284  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599992  4  2193579434  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599993  4  2193579477  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599994  4  2193579489  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599995  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                       4                                                  5  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "5               joy_wolf                      @Kwesidei not the whole crew   \n",
       "6                mybirch                                        Need a hug   \n",
       "7                   coZZ  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
       "8        2Hood4Hollywood               @Tatiana_K nope they didn't have it   \n",
       "9                mimismo                          @twittera que me muera ?   \n",
       "10        erinx3leannexo        spring break in plain city... it's snowing   \n",
       "11          pardonlauren                         I just re-pierced my ears   \n",
       "12                  TLeC  @caregiving I couldn't bear to watch it.  And ...  \n",
       "13       robrobbierobert  @octolinz16 It it counts, idk why I did either...  \n",
       "14           bayofwolves  @smarrison i would've been the first, but i di...  \n",
       "15            HairByJess  @iamjazzyfizzle I wish I got to watch it with ...  \n",
       "16        lovesongwriter  Hollis' death scene will hurt me severely to w...  \n",
       "17              armotley                               about to file taxes   \n",
       "18            starkissed  @LettyA ahh ive always wanted to see rent  lov...  \n",
       "19             gi_gi_bee  @FakerPattyPattz Oh dear. Were you drinking ou...  \n",
       "20                quanvu  @alydesigns i was out most of the day so didn'...  \n",
       "21            swinspeedx  one of my friend called me, and asked to meet ...  \n",
       "22             cooliodoc   @angry_barista I baked you a cake but I ated it   \n",
       "23            viJILLante             this week is not going as i had hoped   \n",
       "24            Ljelli3166                         blagh class at 8 tomorrow   \n",
       "25         ChicagoCubbie     I hate when I have to call and wake people up   \n",
       "26           KatieAngell  Just going to cry myself to sleep after watchi...  \n",
       "27                 gagoo                             im sad now  Miss.Lilly  \n",
       "28               abel209  ooooh.... LOL  that leslie.... and ok I won't ...  \n",
       "29       BaptisteTheFool  Meh... Almost Lover is the exception... this t...  \n",
       "...                  ...                                                ...  \n",
       "1599970    adbillingsley  Thanks @eastwestchic &amp; @wangyip Thanks! Th...  \n",
       "1599971           gekkko  @marttn thanks Martin. not the most imaginativ...  \n",
       "1599972       millerslab          @MikeJonesPhoto Congrats Mike  Way to go!  \n",
       "1599973  luckygeorgeblog  http://twitpic.com/7jp4n - OMG! Office Space.....  \n",
       "1599974    Kristah_Diggs  @yrclndstnlvr ahaha nooo you were just away fr...  \n",
       "1599975        CoachChic  @BizCoachDeb  Hey, I'm baack! And, thanks so m...  \n",
       "1599976         serianna  @mattycus Yeah, my conscience would be clear i...  \n",
       "1599977   TeamUKskyvixen  @MayorDorisWolfe Thats my girl - dishing out t...  \n",
       "1599978      LaurenMoo10                          @shebbs123 i second that   \n",
       "1599979    angel_sammy04                                     In the garden   \n",
       "1599980        puchal_ek  @myheartandmind jo jen by nemuselo zrovna tÃ© ...  \n",
       "1599981    youtubelatest  Another Commenting Contest! [;: Yay!!!  http:/...  \n",
       "1599982  Mandi_Davenport  @thrillmesoon i figured out how to see my twee...  \n",
       "1599983         xoAurixo  @oxhot theri tomorrow, drinking coffee, talkin...  \n",
       "1599984       RobFoxKerr  You heard it here first -- We're having a girl...  \n",
       "1599985         LISKFEST  if ur the lead singer in a band, beware fallin...  \n",
       "1599986          marhgil              @tarayqueen too much ads on my blog.   \n",
       "1599987        cathriiin  @La_r_a NEVEER  I think that you both will get...  \n",
       "1599988          tellman  @Roy_Everitt ha- good job. that's right - we g...  \n",
       "1599989        jazzstixx                 @Ms_Hip_Hop im glad ur doing well   \n",
       "1599990    razzberry5594                              WOOOOO! Xbox is back   \n",
       "1599991        AgustinaP  @rmedina @LaTati Mmmm  That sounds absolutely ...  \n",
       "1599992    sdancingsteph                  ReCoVeRiNg FrOm ThE lOnG wEeKeNd   \n",
       "1599993      ChloeAmisha                                  @SCOOBY_GRITBOYS   \n",
       "1599994        EvolveTom  @Cliff_Forster Yeah, that does work better tha...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Relabel train and test columns with different headings\n",
    "train.columns = ['Sentiment','ID','Time','Query','User','Tweet']\n",
    "test.columns = ['Sentiment','ID','Time','Query','User','Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 2]\n",
      "[0 4]\n"
     ]
    }
   ],
   "source": [
    "## Find unique sentiment values in each dataset\n",
    "print(test.Sentiment.unique())\n",
    "print(train.Sentiment.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO_QUERY'], dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Look at unique queries in both train and test. Due to inconsistency, we agree to remove this column from the analysis\n",
    "train.Query.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kindle2', 'aig', 'jquery', 'twitter', 'obama', 'nike', 'lebron',\n",
       "       'iphone app', 'visa', 'fredwilson', '\"booz allen\"', '40d',\n",
       "       'google', 'itchy', 'stanford', 'lyx', 'Danny Gokey', 'sleep',\n",
       "       'san francisco', 'star trek', 'Malcolm Gladwell', 'espn',\n",
       "       '\"twitter api\"', 'yahoo', 'scrapbooking', 'wolfram alpha', 'weka',\n",
       "       '50d', 'lambda calculus', 'east palo alto', 'lakers',\n",
       "       'north korea', 'pelosi', 'bailout', 'insects', 'mcdonalds', 'exam',\n",
       "       'cheney', 'republican', 'twitter api', 'jquery book',\n",
       "       'goodby silverstein', 'wieden', 'g2', 'googleio',\n",
       "       'viral marketing', '\"night at the museum\"', 'gm', 'time warner',\n",
       "       'china', 'surgery', 'dentist', 'baseball', 'sony', 'safeway',\n",
       "       'eating', 'warren buffet', 'notre dame school', 'federer',\n",
       "       '\"naive bayes\"', 'car warranty call', 'at&t', 'wave sandbox',\n",
       "       'bing', 'summize', 'world cup', 'world cup 2010', 'fred wilson',\n",
       "       'indian election', 'india election', 'comcast',\n",
       "       'shoreline amphitheatre', 'mashable', 'hitler', 'yankees',\n",
       "       'driving', 'visa card', 'Bobby Flay', 'latex', 'iran', 'aapl'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Query.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tweets = train.Tweet\n",
    "target = train.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentiment', 'ID', 'Time', 'Query', 'User', 'Tweet'], dtype='object')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Feature Engineering to look at length of each tweet\n",
    "train.loc[:,'Length'] = [len(t) for t in train.Tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create boxplot showing average length of characters for each tweet\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.boxplot(train.Length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>Awwh babs... you look so sad underneith that s...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuesdayï¿½ll start with reflection ï¿½n then a...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>Whinging. My client&amp;amp;boss don't understand ...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>@TheLeagueSF Not Fun &amp;amp; Furious? The new ma...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>#3 woke up and was having an accident - &amp;quot;...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0</td>\n",
       "      <td>My bathtub drain is fired: it haz 1 job 2 do, ...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>pears &amp;amp; Brie, bottle of Cabernet, and &amp;quo...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0</td>\n",
       "      <td>Have an invite for &amp;quot;Healthy Dining&amp;quot; ...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0</td>\n",
       "      <td>Damnit I was really digging this season of Rea...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0</td>\n",
       "      <td>Why do I keep looking...I know that what I rea...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                              Tweet  Length\n",
       "213           0  Awwh babs... you look so sad underneith that s...     142\n",
       "226           0  Tuesdayï¿½ll start with reflection ï¿½n then a...     141\n",
       "279           0  Whinging. My client&amp;boss don't understand ...     145\n",
       "343           0  @TheLeagueSF Not Fun &amp; Furious? The new ma...     145\n",
       "400           0  #3 woke up and was having an accident - &quot;...     144\n",
       "464           0  My bathtub drain is fired: it haz 1 job 2 do, ...     146\n",
       "492           0  pears &amp; Brie, bottle of Cabernet, and &quo...     150\n",
       "747           0  Have an invite for &quot;Healthy Dining&quot; ...     141\n",
       "957           0  Damnit I was really digging this season of Rea...     141\n",
       "1064          0  Why do I keep looking...I know that what I rea...     141"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Subset data based on useful columns\n",
    "train = train.loc[:,['Sentiment','Tweet','Length']]\n",
    "train[train.Length > 140].head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for Cleaning Data\n",
    "1.\tRemoval of HTML Decoding\n",
    "2.\tRemoval of ‘@’ mentions\n",
    "3.\tRemoval of URL mentions\n",
    "4.\tRemoval of non-UTF-8 characters\n",
    "5.\tRemoval of all punctuation\n",
    "6.\tConvert words to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializations for function\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_cleaner(text):\n",
    "    ## Step 1: take out HTML symbols\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    \n",
    "    ## Step 2: remove all mentions\n",
    "    pat1 = r'@[A-Za-z0-9]+'\n",
    "    \n",
    "    ## Step 3: remove all URLs\n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "    combined_pat = r'|'.join((pat1, pat2))\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    \n",
    "    ## Step 4: remove all non-English characters (clean function in Appendix)\n",
    "    cleaned = clean(stripped)\n",
    "    \n",
    "    ## Step 5: remove all punctuation, but keep hashtags\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", cleaned)\n",
    "    lower_case = letters_only.lower()\n",
    "    \n",
    "    ## Step 6: make all words lowercase\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awww that s a bummer you shoulda got david carr of third day to do it d',\n",
       " 'is upset that he can t update his facebook by texting it and might cry as a result school today also blah',\n",
       " 'i dived many times for the ball managed to save the rest go out of bounds',\n",
       " 'my whole body feels itchy and like its on fire',\n",
       " 'no it s not behaving at all i m mad why am i here because i can t see you all over there',\n",
       " 'not the whole crew',\n",
       " 'need a hug',\n",
       " 'hey long time no see yes rains a bit only a bit lol i m fine thanks how s you',\n",
       " 'k nope they didn t have it',\n",
       " 'que me muera']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing function for cleaner\n",
    "testing = train.Tweet[:10]\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner(t))\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 10000 of 400000 has been processed\n",
      "Tweets 20000 of 400000 has been processed\n",
      "Tweets 30000 of 400000 has been processed\n",
      "Tweets 40000 of 400000 has been processed\n",
      "Tweets 50000 of 400000 has been processed\n",
      "Tweets 60000 of 400000 has been processed\n",
      "Tweets 70000 of 400000 has been processed\n",
      "Tweets 80000 of 400000 has been processed\n",
      "Tweets 90000 of 400000 has been processed\n",
      "Tweets 100000 of 400000 has been processed\n",
      "Tweets 110000 of 400000 has been processed\n",
      "Tweets 120000 of 400000 has been processed\n",
      "Tweets 130000 of 400000 has been processed\n",
      "Tweets 140000 of 400000 has been processed\n",
      "Tweets 150000 of 400000 has been processed\n",
      "Tweets 160000 of 400000 has been processed\n",
      "Tweets 170000 of 400000 has been processed\n",
      "Tweets 180000 of 400000 has been processed\n",
      "Tweets 190000 of 400000 has been processed\n",
      "Tweets 200000 of 400000 has been processed\n",
      "Tweets 210000 of 400000 has been processed\n",
      "Tweets 220000 of 400000 has been processed\n",
      "Tweets 230000 of 400000 has been processed\n",
      "Tweets 240000 of 400000 has been processed\n",
      "Tweets 250000 of 400000 has been processed\n",
      "Tweets 260000 of 400000 has been processed\n",
      "Tweets 270000 of 400000 has been processed\n",
      "Tweets 280000 of 400000 has been processed\n",
      "Tweets 290000 of 400000 has been processed\n",
      "Tweets 300000 of 400000 has been processed\n",
      "Tweets 310000 of 400000 has been processed\n",
      "Tweets 320000 of 400000 has been processed\n",
      "Tweets 330000 of 400000 has been processed\n",
      "Tweets 340000 of 400000 has been processed\n",
      "Tweets 350000 of 400000 has been processed\n",
      "Tweets 360000 of 400000 has been processed\n",
      "Tweets 370000 of 400000 has been processed\n",
      "Tweets 380000 of 400000 has been processed\n",
      "Tweets 390000 of 400000 has been processed\n",
      "Tweets 400000 of 400000 has been processed\n",
      "Tweets 410000 of 800000 has been processed\n",
      "Tweets 420000 of 800000 has been processed\n",
      "Tweets 430000 of 800000 has been processed\n",
      "Tweets 440000 of 800000 has been processed\n",
      "Tweets 450000 of 800000 has been processed\n",
      "Tweets 460000 of 800000 has been processed\n",
      "Tweets 470000 of 800000 has been processed\n",
      "Tweets 480000 of 800000 has been processed\n",
      "Tweets 490000 of 800000 has been processed\n",
      "Tweets 500000 of 800000 has been processed\n",
      "Tweets 510000 of 800000 has been processed\n",
      "Tweets 520000 of 800000 has been processed\n",
      "Tweets 530000 of 800000 has been processed\n",
      "Tweets 540000 of 800000 has been processed\n",
      "Tweets 550000 of 800000 has been processed\n",
      "Tweets 560000 of 800000 has been processed\n",
      "Tweets 570000 of 800000 has been processed\n",
      "Tweets 580000 of 800000 has been processed\n",
      "Tweets 590000 of 800000 has been processed\n",
      "Tweets 600000 of 800000 has been processed\n",
      "Tweets 610000 of 800000 has been processed\n",
      "Tweets 620000 of 800000 has been processed\n",
      "Tweets 630000 of 800000 has been processed\n",
      "Tweets 640000 of 800000 has been processed\n",
      "Tweets 650000 of 800000 has been processed\n",
      "Tweets 660000 of 800000 has been processed\n",
      "Tweets 670000 of 800000 has been processed\n",
      "Tweets 680000 of 800000 has been processed\n",
      "Tweets 690000 of 800000 has been processed\n",
      "Tweets 700000 of 800000 has been processed\n",
      "Tweets 710000 of 800000 has been processed\n",
      "Tweets 720000 of 800000 has been processed\n",
      "Tweets 730000 of 800000 has been processed\n",
      "Tweets 740000 of 800000 has been processed\n",
      "Tweets 750000 of 800000 has been processed\n",
      "Tweets 760000 of 800000 has been processed\n",
      "Tweets 770000 of 800000 has been processed\n",
      "Tweets 780000 of 800000 has been processed\n",
      "Tweets 790000 of 800000 has been processed\n",
      "Tweets 800000 of 800000 has been processed\n",
      "Tweets 810000 of 1200000 has been processed\n",
      "Tweets 820000 of 1200000 has been processed\n",
      "Tweets 830000 of 1200000 has been processed\n",
      "Tweets 840000 of 1200000 has been processed\n",
      "Tweets 850000 of 1200000 has been processed\n",
      "Tweets 860000 of 1200000 has been processed\n",
      "Tweets 870000 of 1200000 has been processed\n",
      "Tweets 880000 of 1200000 has been processed\n",
      "Tweets 890000 of 1200000 has been processed\n",
      "Tweets 900000 of 1200000 has been processed\n",
      "Tweets 910000 of 1200000 has been processed\n",
      "Tweets 920000 of 1200000 has been processed\n",
      "Tweets 930000 of 1200000 has been processed\n",
      "Tweets 940000 of 1200000 has been processed\n",
      "Tweets 950000 of 1200000 has been processed\n",
      "Tweets 960000 of 1200000 has been processed\n",
      "Tweets 970000 of 1200000 has been processed\n",
      "Tweets 980000 of 1200000 has been processed\n",
      "Tweets 990000 of 1200000 has been processed\n",
      "Tweets 1000000 of 1200000 has been processed\n",
      "Tweets 1010000 of 1200000 has been processed\n",
      "Tweets 1020000 of 1200000 has been processed\n",
      "Tweets 1030000 of 1200000 has been processed\n",
      "Tweets 1040000 of 1200000 has been processed\n",
      "Tweets 1050000 of 1200000 has been processed\n",
      "Tweets 1060000 of 1200000 has been processed\n",
      "Tweets 1070000 of 1200000 has been processed\n",
      "Tweets 1080000 of 1200000 has been processed\n",
      "Tweets 1090000 of 1200000 has been processed\n",
      "Tweets 1100000 of 1200000 has been processed\n",
      "Tweets 1110000 of 1200000 has been processed\n",
      "Tweets 1120000 of 1200000 has been processed\n",
      "Tweets 1130000 of 1200000 has been processed\n",
      "Tweets 1140000 of 1200000 has been processed\n",
      "Tweets 1150000 of 1200000 has been processed\n",
      "Tweets 1160000 of 1200000 has been processed\n",
      "Tweets 1170000 of 1200000 has been processed\n",
      "Tweets 1180000 of 1200000 has been processed\n",
      "Tweets 1190000 of 1200000 has been processed\n",
      "Tweets 1200000 of 1200000 has been processed\n",
      "Tweets 1210000 of 1600000 has been processed\n",
      "Tweets 1220000 of 1600000 has been processed\n",
      "Tweets 1230000 of 1600000 has been processed\n",
      "Tweets 1240000 of 1600000 has been processed\n",
      "Tweets 1250000 of 1600000 has been processed\n",
      "Tweets 1260000 of 1600000 has been processed\n",
      "Tweets 1270000 of 1600000 has been processed\n",
      "Tweets 1280000 of 1600000 has been processed\n",
      "Tweets 1290000 of 1600000 has been processed\n",
      "Tweets 1300000 of 1600000 has been processed\n",
      "Tweets 1310000 of 1600000 has been processed\n",
      "Tweets 1320000 of 1600000 has been processed\n",
      "Tweets 1330000 of 1600000 has been processed\n",
      "Tweets 1340000 of 1600000 has been processed\n",
      "Tweets 1350000 of 1600000 has been processed\n",
      "Tweets 1360000 of 1600000 has been processed\n",
      "Tweets 1370000 of 1600000 has been processed\n",
      "Tweets 1380000 of 1600000 has been processed\n",
      "Tweets 1390000 of 1600000 has been processed\n",
      "Tweets 1400000 of 1600000 has been processed\n",
      "Tweets 1410000 of 1600000 has been processed\n",
      "Tweets 1420000 of 1600000 has been processed\n",
      "Tweets 1430000 of 1600000 has been processed\n",
      "Tweets 1440000 of 1600000 has been processed\n",
      "Tweets 1450000 of 1600000 has been processed\n",
      "Tweets 1460000 of 1600000 has been processed\n",
      "Tweets 1470000 of 1600000 has been processed\n",
      "Tweets 1480000 of 1600000 has been processed\n",
      "Tweets 1490000 of 1600000 has been processed\n",
      "Tweets 1500000 of 1600000 has been processed\n",
      "Tweets 1510000 of 1600000 has been processed\n",
      "Tweets 1520000 of 1600000 has been processed\n",
      "Tweets 1530000 of 1600000 has been processed\n",
      "Tweets 1540000 of 1600000 has been processed\n",
      "Tweets 1550000 of 1600000 has been processed\n",
      "Tweets 1560000 of 1600000 has been processed\n",
      "Tweets 1570000 of 1600000 has been processed\n",
      "Tweets 1580000 of 1600000 has been processed\n",
      "Tweets 1590000 of 1600000 has been processed\n",
      "Tweets 1600000 of 1600000 has been processed\n"
     ]
    }
   ],
   "source": [
    "## Actual cleaning of each tweet (all 1.6M)\n",
    "nums = [0,400000,800000,1200000,1600000]\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for j in range(len(nums)-1):\n",
    "    for i in range(nums[j],nums[j+1]):\n",
    "        if( (i+1)%10000 == 0 ):\n",
    "            print(\"Tweets %d of %d has been processed\" % ( i+1, nums[j+1] ))\n",
    "        clean_tweet_texts.append(tweet_cleaner(train.loc[i,'Tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that s a bummer you shoulda got david car...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2  i dived many times for the ball managed to sav...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it s not behaving at all i m mad why am i h...       0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create new dataframe for cleaned tweets\n",
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df['target'] = train.Sentiment\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsmith/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that s a bummer you shoulda got david car...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2  i dived many times for the ball managed to sav...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it s not behaving at all i m mad why am i h...       0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Put new dataframe of cleaned tweets into csv file\n",
    "clean_df.to_csv('clean_train.csv',encoding='utf-8')\n",
    "my_df = pd.read_csv('clean_train.csv',index_col=0)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['Tweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Using clean code to clean test dataset\n",
    "nums = [0,len(test)]\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_test_texts = []\n",
    "for j in range(len(nums)-1):\n",
    "    for i in range(nums[j],nums[j+1]):\n",
    "        if( (i+1)%10000 == 0 ):\n",
    "            print(\"Tweets %d of %d has been processed\" % ( i+1, nums[j+1] ))\n",
    "        clean_test_texts.append(tweet_cleaner(test.loc[i,'Tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i loooooooovvvvvveee my kindle not that the dx...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reading my kindle love it lee childs is good read</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ok first assesment of the kindle it fucking rocks</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you ll love your kindle i ve had mine for a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fair enough but i have the kindle and i think ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  i loooooooovvvvvveee my kindle not that the dx...       4\n",
       "1  reading my kindle love it lee childs is good read       4\n",
       "2  ok first assesment of the kindle it fucking rocks       4\n",
       "3  you ll love your kindle i ve had mine for a fe...       4\n",
       "4  fair enough but i have the kindle and i think ...       4"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creat new test dataset using cleaned data\n",
    "clean_test = pd.DataFrame(clean_test_texts,columns=['text'])\n",
    "clean_test['target'] = test.Sentiment\n",
    "clean_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove or change neutral test data labels using NLTK Vader sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.loc[inds[2],'text'] = 'i want to go to promote gear and groove but unfortunately no ride there i may b going to the one in anaheim in may though'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check this video out president obama at the white house correspondents dinner\n",
      "\n",
      "need suggestions for a good ir filter for my canon d got some pls dm\n",
      "2\n",
      "[0.    0.276]\n",
      "4\n",
      "\n",
      "i just checked my google for my business blip shows up as the second entry huh is that a good or ba emhv\n",
      "2\n",
      "[0.    0.127]\n",
      "4\n",
      "\n",
      "is in san francisco at bay to breakers\n",
      "\n",
      "just landed at san francisco\n",
      "\n",
      "san francisco today any suggestions\n",
      "\n",
      "on my way to see star trek the esquire\n",
      "\n",
      "going to see star trek soon with my dad\n",
      "\n",
      "bill simmons in conversation with malcolm gladwell\n",
      "\n",
      "playing with curl and the twitter api\n",
      "2\n",
      "[0.    0.231]\n",
      "4\n",
      "\n",
      "playing with java and the twitter api\n",
      "2\n",
      "[0.    0.231]\n",
      "4\n",
      "\n",
      "nike owns nba playoffs ads w lebron kobe carmelo adidas billups howard marketing branding\n",
      "\n",
      "next time i ll call myself nike\n",
      "\n",
      "new blog post nike sb dunk low premium white gum\n",
      "2\n",
      "[0.189 0.   ]\n",
      "0\n",
      "\n",
      "giving weka an app engine interface using the bird strike data for the tests the logo is a given\n",
      "2\n",
      "[0.075 0.121]\n",
      "4\n",
      "\n",
      "brand new canon eos d mp dslr camera canon mm is lens web technology thread brand new canon eos\n",
      "\n",
      "nvidia names stanford s bill dally chief scientist vp of research\n",
      "\n",
      "new blog post harvard versus stanford who wins\n",
      "2\n",
      "[0.    0.346]\n",
      "4\n",
      "\n",
      "jquery ui book review c\n",
      "\n",
      "at gwt fireside chat\n",
      "\n",
      "hi there does anyone have a great source for advice on viral marketing\n",
      "2\n",
      "[0.    0.272]\n",
      "4\n",
      "\n",
      "here s a case study on how to use viral marketing to add over people to your list\n",
      "\n",
      "going to see the new night at the museum movie with my family oh boy a three year old in the movies fuin\n",
      "\n",
      "just saw the new night at the museum movie it was okay lol\n",
      "2\n",
      "[0.    0.299]\n",
      "4\n",
      "\n",
      "going to see night at the museum with tall boy\n",
      "\n",
      "i saw night at the museum battle of the swithsonian today it was okay your typical kids ben stiller movie\n",
      "2\n",
      "[0.121 0.088]\n",
      "0\n",
      "\n",
      "taking katie to see night at the museum she picked it\n",
      "\n",
      "gm says expects announcment on sale of hummer soon reuters wdsugm says expects announcment on sale of hummer\n",
      "\n",
      "time warner cable pulls the plug on the girlfriend experience www tinyurl com m fk\n",
      "\n",
      "rocawear heads to china building stores\n",
      "\n",
      "climate focus turns to beijing the united nations the us and european governments have called on china to co o\n",
      "2\n",
      "[0.    0.135]\n",
      "4\n",
      "\n",
      "myfoxdc barrie students back from trip to china a silver spring high school s class trip to china has en\n",
      "\n",
      "three china aerospace giants develop tianjin binhai new area b yuan invested\n",
      "\n",
      "gm ceo china will continue to be key partner\n",
      "\n",
      "rt is now the time to buy a gm car\n",
      "\n",
      "dentist tomorrow have to brush well in the morning like i make my hair all nice before i get it cut why\n",
      "2\n",
      "[0.082 0.29 ]\n",
      "4\n",
      "\n",
      "pet dentist\n",
      "\n",
      "ncaa baseball super regional rams club\n",
      "2\n",
      "[0.    0.438]\n",
      "4\n",
      "\n",
      "just started playing major league baseball k\n",
      "2\n",
      "[0.    0.265]\n",
      "4\n",
      "\n",
      "cardinals baseball advance to super regionals face cs fullerton friday\n",
      "2\n",
      "[0.    0.302]\n",
      "4\n",
      "\n",
      "sony coupon code expires soon\n",
      "\n",
      "waiting in line at safeway\n",
      "\n",
      "did not realize there is a gym above safeway\n",
      "\n",
      "i have three words for you safeway dot com\n",
      "\n",
      "bout to hit safeway i gotta eat\n",
      "\n",
      "jake s going to safeway\n",
      "\n",
      "found a safeway picking up a few staples\n",
      "\n",
      "safeway super marketing via mobile coupons\n",
      "2\n",
      "[0.    0.438]\n",
      "4\n",
      "\n",
      "your normal weight and how to get there normal eating blog\n",
      "\n",
      "is eating and watching movies\n",
      "\n",
      "eating sashimi\n",
      "\n",
      "is eating home made yema\n",
      "\n",
      "eating cake\n",
      "\n",
      "iphone may get radio tagging and nike recently released itunes version suggests that voiceover functional\n",
      "\n",
      "launched imgsearch ajax jquery webapp\n",
      "2\n",
      "[0.    0.273]\n",
      "4\n",
      "\n",
      "rt the ultimate jquery list\n",
      "\n",
      "i just extracted and open sourced a jquery plugin from stormweight to highlight text with a regular expression\n",
      "2\n",
      "[0.    0.146]\n",
      "4\n",
      "\n",
      "debenham what was the php jquery hack\n",
      "\n",
      "jquery cheat sheet\n",
      "2\n",
      "[0.6 0. ]\n",
      "0\n",
      "\n",
      "beginning javascript and css development with jquery javascript css jquery\n",
      "\n",
      "warren buffet on the economy\n",
      "\n",
      "all star basketball classic tuesday features top talent chattanooga s notre dame high school will play host\n",
      "2\n",
      "[0.   0.35]\n",
      "4\n",
      "\n",
      "rt look available amazon kindle kindle dx get it here the top electronic book reader period free day ship\n",
      "2\n",
      "[0.155 0.264]\n",
      "4\n",
      "\n",
      "man accosts roger federer during french open\n",
      "\n",
      "investigation pending on death of stanford cs prof google mentor rajeev motwani tip\n",
      "2\n",
      "[0.245 0.   ]\n",
      "0\n",
      "\n",
      "i m going to bed it was a successful weekend stanford here i come\n",
      "2\n",
      "[0.    0.297]\n",
      "4\n",
      "\n",
      "google wave developer sandbox account request\n",
      "\n",
      "have google profiles stopped showing up in searches cant see them anymore\n",
      "2\n",
      "[0.147 0.   ]\n",
      "0\n",
      "\n",
      "any twitter to aprs apps yet\n",
      "\n",
      "pros you should be following on twitter\n",
      "\n",
      "share disruption fred wilson s slides for his talk at google hq\n",
      "2\n",
      "[0.182 0.161]\n",
      "0\n",
      "\n",
      "ok do nothing just thinking about d\n",
      "2\n",
      "[0.    0.306]\n",
      "4\n",
      "\n",
      "rt rt gm onstar now instantly sends accident location coordinates to gps obsessed\n",
      "2\n",
      "[0.304 0.   ]\n",
      "0\n",
      "\n",
      "breakers in san francisco ca\n",
      "\n",
      "heading to san francisco\n",
      "\n",
      "how do you use the twitter api\n",
      "\n",
      "testing twitter api\n",
      "\n",
      "testing twitter api remote update\n",
      "\n",
      "new blog post nike zoom lebron soldier iii white black teal\n",
      "\n",
      "new blog post nike trainer\n",
      "\n",
      "jobs sittercity help with taking care of sick child east palo alto ca\n",
      "2\n",
      "[0.172 0.307]\n",
      "4\n",
      "\n",
      "mba admissions tips stanford gsb deadlines and essay topics\n",
      "\n",
      "ethics and nonprofits stanford socialentrepreneurship\n",
      "\n",
      "learning jquery book review c\n",
      "\n",
      "adobe cs commercial by goodby silverstein\n",
      "\n",
      "watching a programme about the life of hitler its only enhancing my geekiness of history\n",
      "\n",
      "jenna i went to see night at the museum today and i was so surprised to see three cast members from the office\n",
      "2\n",
      "[0.    0.111]\n",
      "4\n",
      "\n",
      "about to watch night at the museum with ryan and stacy\n",
      "\n",
      "getting ready to go watch night at the museum dum dum you give me gum gum\n",
      "2\n",
      "[0.    0.143]\n",
      "4\n",
      "\n",
      "i think i may have a new favorite restaurant on our way to see night at the museum\n",
      "2\n",
      "[0.    0.176]\n",
      "4\n",
      "\n",
      "up was sold out so i m seeing night at the museum i m years old\n",
      "\n",
      "obama nationalization of gm to be short term ap\n",
      "\n",
      "time warner ceo hints at online fees for magazines ap read from mountain view united states views\n",
      "2\n",
      "[0.    0.149]\n",
      "4\n",
      "\n",
      "lawson to head newedge hong kong business china\n",
      "\n",
      "weird piano guitar house in china\n",
      "2\n",
      "[0.254 0.   ]\n",
      "0\n",
      "\n",
      "send us your gm chevy photos\n",
      "\n",
      "i had a dentist appt this morning and had the same conversation\n",
      "\n",
      "check this video out david after dentist\n",
      "\n",
      "first dentist appointment in years on wednesday possibly\n",
      "\n",
      "tom shanahan s latest column on sdsu and its ncaa baseball regional appearance\n",
      "\n",
      "baseballamerica com blog baseball america prospects blog blog\n",
      "2\n",
      "[0.    0.239]\n",
      "4\n",
      "\n",
      "portland city politics may undo baseball park\n",
      "\n",
      "rt ca merced s water bottled by safeway resold at a profit wells are drying up across the county\n",
      "2\n",
      "[0.    0.246]\n",
      "4\n",
      "\n",
      "dropped her broccoli walking home from safeway so depressed\n",
      "2\n",
      "[0.346 0.   ]\n",
      "0\n",
      "\n",
      "we don t have safeway\n",
      "\n",
      "at safeway with dad\n",
      "\n",
      "safeway with marvin janelle and auntie lhu\n",
      "\n",
      "safeway offering mobile coupons\n",
      "\n",
      "phillies driving in the cadillac with the top down in cali win\n",
      "2\n",
      "[0.    0.359]\n",
      "4\n",
      "\n",
      "saved money by opting for grocery store trip and stocking food in hotel room fridge vs eating out every night while out of town\n",
      "2\n",
      "[0.    0.109]\n",
      "4\n",
      "\n",
      "lounging around eating taco bell and watching ncis before work tonight need help staying awake\n",
      "2\n",
      "[0.    0.162]\n",
      "4\n",
      "\n",
      "eating breakfast and then school\n",
      "\n",
      "still hungry after eating\n",
      "\n",
      "tips for healthy eating resultsby fitness blog fitness\n",
      "2\n",
      "[0.   0.58]\n",
      "4\n",
      "\n",
      "with the boyfriend eating a quesadilla\n",
      "\n",
      "eating dinner meat chips and risotto\n",
      "\n",
      "got a new pair of nike shoes pics up later\n",
      "\n",
      "nike sb blazer high acg custom brad douglas\n",
      "\n",
      "nike air yeezy khaki pink colorway release\n",
      "\n",
      "that looks an awful lot like one of nike s private jets i m just sayin\n",
      "2\n",
      "[0.182 0.152]\n",
      "0\n",
      "\n",
      "devsnippets jquery tools javascript ui components for the web\n",
      "\n",
      "all about ajax jquery css javascript and more many examples\n",
      "\n",
      "this is cold i was looking at google s chart visualization api and found this jquery wrapper for the api\n",
      "\n",
      "i spent most of my day reading a jquery book now to start drinking some delirium tremens\n",
      "\n",
      "jquery selectors\n",
      "\n",
      "how to implement a news ticker with jquery and ten lines of code\n",
      "\n",
      "what s buffet doing warren buffett kicks butt in battle of the boots posted by alex crippe\n",
      "2\n",
      "[0.148 0.   ]\n",
      "0\n",
      "\n",
      "i m truly braindead i couldn t come up with warren buffet s name to save my soul\n",
      "2\n",
      "[0.    0.357]\n",
      "4\n",
      "\n",
      "oh i see i thought at t were mhz wcdma\n",
      "\n",
      "where did you read about tethering support phil just at t or will o be joining in\n",
      "2\n",
      "[0.    0.162]\n",
      "4\n",
      "\n",
      "i hope the girl at work buys my kindle\n",
      "2\n",
      "[0.    0.293]\n",
      "4\n",
      "\n",
      "missed this insight filled may column one smart guy looking closely at why he s impressed with kindle\n",
      "2\n",
      "[0.1   0.264]\n",
      "4\n",
      "\n",
      "gem my primary debit card is visa electron\n",
      "\n",
      "off to the bank to get my new visa platinum card\n",
      "\n",
      "has a date with bobby flay and gut fieri from food network\n",
      "\n",
      "how to track iran with social media\n",
      "\n",
      "twitter stock buzz aapl es f spy spx palm updated pm\n",
      "\n",
      "is bobby flay joining you\n",
      "\n",
      "ask programming latex or indesign submitted by calcio link comment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Use vader sentiment analysis to compute sentiment regarding neutral tweets\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "## Subset test data to only analyze neutral data points\n",
    "sentences = clean_test[clean_test['target'] == 2].loc[:,'text']\n",
    "target = clean_test[clean_test['target'] == 2].loc[:,'target']\n",
    "inds = target.index.values\n",
    "i = 0\n",
    "l = ['neg','pos']\n",
    "test1 = clean_test\n",
    "\n",
    "## Run analysis through each sentence\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    \n",
    "    ## Compute each positive and negative polarity score for each sentence\n",
    "    vals = np.zeros(2)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    vals[0] = ss[l[0]]\n",
    "    vals[1] = ss[l[1]]\n",
    "    \n",
    "    ## Remove test data point if both positive and negative probabilities are zero.\n",
    "    if vals[0] == vals[1] and vals[0] == 0:\n",
    "        test1 = test1.drop(inds[i])\n",
    "    \n",
    "    ## Otherwise initialize each sentence as positive or negative depending on higher accuracy \n",
    "    else:\n",
    "        print(test1.loc[inds[i],'target'])\n",
    "        print(vals)\n",
    "        if vals[0] > vals[1]:\n",
    "            test1.loc[inds[i],'target'] = 0\n",
    "        else:\n",
    "            test1.loc[inds[i],'target'] = 4\n",
    "        print(test1.loc[inds[i],'target'])\n",
    "    print()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i loooooooovvvvvveee my kindle not that the dx...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reading my kindle love it lee childs is good read</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ok first assesment of the kindle it fucking rocks</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you ll love your kindle i ve had mine for a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fair enough but i have the kindle and i think ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  i loooooooovvvvvveee my kindle not that the dx...       4\n",
       "1  reading my kindle love it lee childs is good read       4\n",
       "2  ok first assesment of the kindle it fucking rocks       4\n",
       "3  you ll love your kindle i ve had mine for a fe...       4\n",
       "4  fair enough but i have the kindle and i think ...       4"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now create new dataframe for cleaned test data and save to csv\n",
    "test1.to_csv('clean_test.csv',encoding='utf-8')\n",
    "my_df = pd.read_csv('clean_test.csv',index_col=0)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Code used for better testing cleaning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Whinging. My client&amp;boss don't understand English well. Rewrote some text unreadable. It's written by v. good writer&amp;reviewed correctly. \""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Tweet[279]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whinging. My client&boss don't understand English well. Rewrote some text unreadable. It's written by v. good writer&reviewed correctly. \n"
     ]
    }
   ],
   "source": [
    "## Practice code for cleaning HTML decoding\n",
    "from bs4 import BeautifulSoup\n",
    "example1 = BeautifulSoup(train.Tweet[279], 'lxml')\n",
    "print(example1.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@TheLeagueSF Not Fun &amp; Furious? The new mantra for the Bay 2 Breakers? It was getting 2 rambunctious;the city overreacted &amp; clamped down '"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Tweet[343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Not Fun &amp; Furious? The new mantra for the Bay 2 Breakers? It was getting 2 rambunctious;the city overreacted &amp; clamped down '"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Practice code for cleaning mentions\n",
    "import re\n",
    "re.sub(r'@[A-Za-z0-9]+','',train.Tweet[343])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existing research also mentions that URL's do not provide enough information to really help the model, thus they can be ignored. These values can be seen as positively or negatively, thus don't add enough value to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot  - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Practice code for cleaning HTML decoding\n",
    "re.sub('https?://[A-Za-z0-9./]+','',train.Tweet[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at non-unicode values, I'm taking out all non-unicode values and replacing them with a ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tuesdayï¿½ll start with reflection ï¿½n then a lecture in Stress reducing techniques. That sure might become very useful for us accompaniers '"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Tweet[226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tuesday?ll start with reflection ?n then a lecture in Stress reducing techniques. That sure might become very useful for us accompaniers '"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Function for cleaning all non-unicode changing all non-unicode characters to ?\n",
    "def clean(string):\n",
    "    new_str = ''\n",
    "    for i in range(len(string)):\n",
    "        if ord(string[i]) >= 128:\n",
    "            if len(new_str) == 0:\n",
    "                new_str += '?'\n",
    "            else:\n",
    "                if new_str[-1] == '?':\n",
    "                    new_str += ''\n",
    "                else:\n",
    "                    new_str += '?'\n",
    "        else:\n",
    "            new_str += string[i]\n",
    "    return new_str\n",
    "clean(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look through each Tweet, take out all non letter values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@machineplay I'm so sorry you're having to go through this. Again.  #therapyfail\""
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Tweet[175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' machineplay I m so sorry you re having to go through this  Again    therapyfail'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Practice code for cleaning all punctuation\n",
    "re.sub(\"[^a-zA-Z0-9]\", \" \", train.Tweet[175])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "clean_f = lambda text: re.sub(\"fuck\",\"f***\",text)\n",
    "clean_s = lambda text: re.sub(\"shit\",\"s***\",text)\n",
    "clean_b = lambda text: re.sub(\"bitch\",\"b****\",text)\n",
    "clean_d = lambda text: re.sub(\"dick\",\"d***\",text)\n",
    "clean = [clean_f,clean_s,clean_b,clean_d]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
